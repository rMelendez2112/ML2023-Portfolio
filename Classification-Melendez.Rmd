---
title: "Classification on DnD Character Data Set"
author: "Rafael Melendez"
output:
  html_notebook
editor_options:
  chunk_output_type: inline
---

https://github.com/rMelendez2112/ML2023-Portfolio/blob/936b6cd95062085978e56db4d231e803ceff0b9a/Classification-Melendez.Rmd

```{r}
dndStats <- "C:\\Users\\bayon\\OneDrive\\Documents\\stats.csv"
content <- read.csv(dndStats)

print(content)


sdata <- read.csv("C:\\Users\\bayon\\OneDrive\\Documents\\stats.csv", header = TRUE, sep = ",")
sdata
```

### Divide into 80/20 Test & Train set
```{r}
#A
str(sdata)

set.seed(1234)
i <- sample(1:nrow(sdata), nrow(sdata)*0.8, replace=FALSE)
train <- sdata[i,]
test <- sdata[-i,]

#B
names(sdata)
ncol(sdata)
tail(sdata, n = 10)
colSums(is.na(sdata))
summary(sdata)
```

### Create 2 Informative Graphs
```{r}
#C

plot(sdata$weight~sdata$height, xlab = "Height", ylab = "Weight")
abline(lm(sdata$weight~sdata$height), col="aquamarine")

plot(sdata$charisma~sdata$height, xlab = "Height", ylab = "Charisma")
abline(lm(sdata$weight~sdata$height), col = "aquamarine")
```

### Build a Logistic Regression Model
```{r}
#D

glm1 <- glm(as.factor(race)~height, data = train, family = "binomial")
summary(glm1)
```

### Build a Naïve Bayes Model
```{r}
#install.packages("e1071")
library(e1071)
nb1 <- naiveBayes(race~., data = train)
nb1
```

```{r}
p1 <- predict(nb1, newdata = test, type = "class")
table(p1, test$height)
mean(p1 == test$height)
```

```{r}
#F


```


#G
Some advantages of the Naïve Bayes algorithm include its ability to perform 
multi-class predictions along with a quick processing time. Its disadvantages
include its assumption that features are all independent and computational cost.
Logistic Regression models are, in comparison, more approachable/easier to train on 
and don't make assumptions about features in a dataset. Still, Logistic Regression models 
are limited to discrete functions and are bound to a certain range.

#H
Mean squared error is a good metric to make sure that possible outliers in a 
dataset don't create wildly inaccurate predictions. It, however, runs a small chance 
of making an outlier worse on the predicted data.
RMSE places a priority on errors in the data set to single out larger errors. A disadvantage 
of RMSE is that it cannot function as optimally in the presence of outliers.
Correlation is a low-cost, relatively straightforward metric. Still, correlation does 
not equal causation and may fall flat in the presence of more indicative, complex metrics.


